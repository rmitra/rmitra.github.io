<!doctype html>
<!--
  Material Design Lite
  Copyright 2015 Google Inc. All rights reserved.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      https://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License
-->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="A front-end template that helps you build fast, modern mobile web apps.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <title>Material Design Lite</title>

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <link rel="icon" sizes="192x192" href="images/android-desktop.png">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Material Design Lite">
    <link rel="apple-touch-icon-precomposed" href="images/ios-desktop.png">

    <!-- Tile icon for Win8 (144x144 + tile color) -->
    <meta name="msapplication-TileImage" content="images/touch/ms-touch-icon-144x144-precomposed.png">
    <meta name="msapplication-TileColor" content="#3372DF">

    <link rel="shortcut icon" href="images/favicon.png">

    <!-- SEO: If your mobile URL is different from the desktop URL, add a canonical link to the desktop page https://developers.google.com/webmasters/smartphone-sites/feature-phones -->
    <!--
    <link rel="canonical" href="http://www.example.com/">
    -->

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:regular,bold,italic,thin,light,bolditalic,black,medium&amp;lang=en">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.deep_purple-pink.min.css">
    <link rel="stylesheet" href="styles.css">
    <style>
    #view-source {
      position: fixed;
      display: block;
      right: 0;
      bottom: 0;
      margin-right: 40px;
      margin-bottom: 40px;
      z-index: 900;
    }
    </style>
  </head>
  <body class="mdl-demo mdl-color--grey-100 mdl-color-text--grey-700 mdl-base">
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
      <header class="mdl-layout__header mdl-layout__header--scroll mdl-color--primary">
        <div class="mdl-layout--large-screen-only mdl-layout__header-row">
        </div>
        <div class="mdl-layout--large-screen-only mdl-layout__header-row">
          <h3>3D Modelling From Images using Semi Supervised Learning</h3>
        </div>
        <div class="mdl-layout--large-screen-only mdl-layout__header-row">
        </div>
        <div class="mdl-layout__tab-bar mdl-js-ripple-effect mdl-color--primary-dark">
          <a href="#abstract" class="mdl-layout__tab is-active">Abstract</a>
          <a href="#overview" class="mdl-layout__tab">Thesis Overview</a>
          <a href="#localfeatures1" class="mdl-layout__tab">PhotoSynth Dataset</a>
          <a href="#localfeatures2" class="mdl-layout__tab">Scale Invariant Local Features</a>
          <a href="#semisuppose" class="mdl-layout__tab">Semi Supervised Human Pose Estimation</a>
          <a href="#unsuptex" class="mdl-layout__tab">Unsupervised Human Texture Synthesis</a>
        </div>
      </header>
      <main class="mdl-layout__content">
        <div class="mdl-layout__tab-panel is-active" id="abstract">
          <section class="section--center mdl-grid mdl-grid--no-spacing mdl-shadow--2dp">
            <div class="mdl-card mdl-cell mdl-cell--9-col-desktop mdl-cell--6-col-tablet mdl-cell--4-col-phone" style="width: 100%">
              <div class="mdl-card__supporting-text" style="text-align: justify;">
                <h4 style="text-align: center;">Abstract</h4>
                <p>Modelling the world in 3D has been a long standing problem in computer vision. A large variety of techniques exits for 3D modelling from a single image or a collection of images specific to different applications. Among them two widely used techniques are i) Structure-From-Motion (SFM) which reconstructs 3D point clouds of an environment from a collection of images, ii) modelling of a human subject in 3D from a single RGB image. In my thesis I have focused on mitigating some of current issues faced by these methods. I have proposed semi-supervised deep learning techniques which can utilise large volumes of un-annotated in-the-wild datasets to improve accuracy of existing 3D modelling techniques.</p>
                <p>Finding point correspondences between images using local patch descriptors like SIFT is an essential step in reconstructing 3D using SFM. Currently CNN based descriptor models hold state-of-the-art performance in finding point correspondences. To further improve their the accuracy, we provide a framework to automatically generate pairs of similar and dissimilar patches from a large in-the-wild dataset(PS-Dataset) of image collections exhibiting wide variations in viewpoint and illumination.</p>
                <p>The robustness of a descriptor to scale is largely attributed to normalising patches in terms of scale before computing its descriptors. However, in certain applications like dense matching of pixels between two images normalising patches is infeasible due to unavailability of scale information at every pixel. Hence, I propose a multi-resolution architecture CNN model to compute scale invariant descriptors without requiring any normalisation. We perform correspondence matching and 3D reconstruction on benchmark datasets using such non-normalized patches to demonstrate its efficacy.</p>
                <p>In modelling humans from monocular images, current fully supervised methods requires large amounts 3D annotated images which are captured in indoor settings using sophisticated motion capture setups. Hence, these methods do not generalise well to in-the-wild settings. To this end, we propose a semi-supervised approach which can utilise multi-view images captured in the wild without requiring 3D annotations. In our approach, we jointly learn i) an embedding capturing 3D human pose from multi-view images using metric learning and ii) to estimate 3D joint locations from our embedding using little amount of 3D supervision.</p>
                <p>To have a complete representation of a human subject digitally, a fully textured mesh model is essential. In this regard, we present a unsupervised framework that estimates textures of the human subject given a single RGB image and an estimated mesh. We enhance the efficacy of an existing framework that learn to generate textures by ensuring consistency between textures obtained from multiple images of the same subject during training. We achieve this by hierarchically refining the mesh such that its projection has a higher overlap with the human subject enabling higher consistency between textures.</p>
                <p>We perform extensive experiments for all proposed methods on publicly available benchmark datasets and outperform corresponding competing methods.</p>
              </div>
            </div>
          </section>
        </div>
        <div class="mdl-layout__tab-panel" id="overview">
          <section class="section--center mdl-grid mdl-grid--no-spacing">
            <div class="mdl-cell mdl-cell--12-col">
              <p style="text-align: justify;">Perceiving the world in 3D is essential for an autonomous robot for carrying out several tasks such as navigating, interacting with other people or objects, analysing structures and so on. Humans are excellent in estimating relative depth and 3D structure of contents in a scene through evolution. Achieving similar levels of accuracy through machines forms a fundamental problem in computer vision and is actively pursued in the community. A large variety of ongoing techniques for 3D reconstruction exist in the literature specific to different applications. For instance, the method of Structure-From-Motion (SFM), Simultaneous Localization And Mapping (SLAM) are used for reconstructing an entire environment while dedicated methods exploiting human structure exist for modelling people in 3D from images and videos. In my thesis, I have focused on mitigating some of the issues faced by current method solving SFM and monocular 3D Human modelling.</p>
              <h3 style="text-align: center;">Contributions</h3>
              <p style="text-align: center;"><img src="images/Visual Contribution Map.jpg"></p>
              <h6 style="text-align: center;">Visual Map of my contributions</h6>

              <br><br>
              <p style="text-align: justify;">I address the problem of exploiting massive unlabelled in-the-wild datasets for different learning frameworks pertaining to improve performance of 3D modelling of scenes and humans. My contributions span several aspects of learning from data,</p>
              
              <ul style="text-align: justify;">
                <li>Create a dataset consisting of images of real world scenes. Automatically process the images to create training data with labels for the task at hand. These labels does not require manual interventions but uses off-the-shelf techniques along with other specific constraints. The generated labels at times can be noisy and suffer slight deviations from the ground truth. The large volume of datasets ensures the effect of such noisy labels are negligible.</li>
                <li>Design novel deep learning architecture to account for wide variations while learning specific tasks from real `in-the-wild' datasets.</li>
                <li>Adopt semi-supervised approaches where the model is jointly trained on large amounts in-the-wild unlabelled data and much smaller set of labelled data. The labelled data is required to supervise the model for task specific outputs(eg. predicting 3D body joint locations) while weak supervision/constraints are used learn from the unlabelled data. The quantity and in-the-wild variations in the unlabelled data enables the model to learn robust intermediate feature maps that can be applied in real world scenarios.</li>
                <li>Adopt un-supervised approaches where only weak constraints are used for learning. In this setting no annotations are required and are used in problems which even small amounts of ground truth labels are not available.</li>
              </ul>

              <br>
              <h3 style="text-align: center;">Applications</h3>
              <br>
              <h4 style="text-align: left;">SFM Applications</h4>
              <p style="text-align: center;"><img style="width: 90%" src="images/SFM Applications.jpg"></p>
              <h6 style="text-align: justify;"><b>Photo Tourism</b>[1]: 3D modelling of popular sites and landscapes from large collection of photos from the internet. <b>Augmented Reality</b>[2]: Annotate images based on 3D structure. <b>Structural Geology</b>[3]: Images from Unmanned Aerial Vehicles (UAV) are used to reconstruct 3D surface for high fidelity surveys of trenches and rock exposures.</h6>
              
              <br>
              
              <h4 style="text-align: left;">Human Modelling Applications</h4>
              <p style="text-align: center;"><img style="width: 90%" src="images/Human Pose Applications.jpg"></p>
              <h6 style="text-align: justify;"><b>Markerless Motion Capture</b>[4]: Capture human motions in free environments without markers, widely used for film making. <b>Digital Avatar</b>>[5]: Creating an animatable object representing the subject from a single RGB image. <b>Interactive Applications</b>[6]: Creating applications which can be used by body movements, e.g. Interactive Art.</h6>
                         
              <br>
         
            </div>
          </section>
        </div>
        <div class="mdl-layout__tab-panel" id="localfeatures1">
          <section class="section--center mdl-grid mdl-grid--no-spacing">
            <div class="mdl-cell mdl-cell--12-col">
              <p style="text-align: justify;">To enhance the performance of CNN based descriptors, we introduce a novel dataset that overcomes many of the drawbacks of existing datasets used of training descriptors. We begin with collecting data from publicly available large collection of images from the internet which are taken in-the-wild and exhibit wide variations in content, viewpoints, scale and illumination. We use Microsoft PhotoSynth for this purpose. We collected 30 scenes with each scene comprising of a collection of around 250 images appx. Sample images from different are shown below,</p>
              <p style="text-align: center;"><img style="width: 90%" src="images/PS_Dataset_Images.jpg"></p>
              <h6 style="text-align: center;">Sample pairs of images from our proposed dataset showing viewpoint, scale and illumination variations</h6>

              <br>
              <p style="text-align: justify;">Next, we propose an automated way to process these image collections to generate pairs of ‘positive’ (similar) and ‘negative’ (dissimilar) patches that can be used to learn descriptors from patches through metric learning shown below,</p>
              <p style="text-align: center;"><img style="width: 90%" src="images/PS_Dataset_patches.jpg"></p>
              <h6 style="text-align: center;">Patches extracted by our algorithm centered around keypoints shown in green dots representing a unique 3D point in the scene.</h6>

              <br>

              <p style="text-align: justify;">We exploit the Structure From Motion process and its outputs to generate the desired data. Specifically, we perform SFM on each of the image collections using SIFT descriptors for point correspondences. The SFM process outputs i) reconstructed 3D points ii) set of corresponding 2D locations from images corresponding to each 3D point, ii) estimated intrinsic and extrinsic parameters. The transitivity relationship between point correspondences(i.e.a correspondence between pair of images (A, B) and (B,C) ensures correspondence between pairs (A, C)).
              This enables the SFM process to match corresponding points between pair (A, C) which would been otherwise unlikely to obtain when matched directly using SIFT descriptors. The set of corresponding 2D locations given a 3D point may contain images that are taken from very similar viewpoints and scale. We propose a novel algorithm to prune out these near duplicate entries from the set using estimated intrinsic and extrinsic camera parameters. Our pruning algorithm is also be used to customise the amount of variability between corresponding pairs in terms viewpoints and scale for different tasks.
              State-of-the-art descriptor learning frameworks trained on our proposed dataset outperform significantly those that are trained existing datasets on matching point correspondences.</p>
            </div>
          </section>
        </div>
        <div class="mdl-layout__tab-panel" id="localfeatures2">
          <section class="section--center mdl-grid mdl-grid--no-spacing">
            <div class="mdl-cell mdl-cell--12-col">
              <p style="text-align: justify;">
                The CNN based descriptor models mentioned previously operates on patches which are normalised in
                terms of scale and rotation. As a consequence, the normalized patch ensures the descriptor computed are
                in turn invariant to scale and rotation. The normalisation requires 'scale' and 'dominant orientation' values
                which are evaluated by the keypoint detector and provided along with the location for each detected point.
                However, in certain applications like densely matching
                every pixel(not just keypoints) lying in the shared region between two images, the 'scale' and 'orientation'
                values are not available. To improve matching accuracy in such scenarios, we propose a multi-resolution
                CNN architecture to encode descriptors without requiring normalisation yet achieving invariance to scale.
                In this architecture, the network takes in patches cropped at 3 different resolutions centered around the
                same point and extracts feature maps using the same feature extractor, concatenates the features and finally
                encodes them into the output descriptor. Using features from patches cropped at different resolution helps in
                capturing information at different scales. Our proposed architecture trained on our novel dataset using metric
                learning outperforms competing methods when input patches are not normalized. We also demonstrate the
                superior SFM based 3D reconstruction on benchmark <b>Strecha</b> dataset when point correspondences are
                obtained using descriptors computed by our model on non-normalised patches in the following figure.
              </p>
              <p style="text-align: center;"><img style="width: 90%" src="images/reconstruction-teaser.jpg"></p>
              <h6 style="text-align: justify;">
                Comparing reconstruction obtained from SFM on the 'fountain' scene of Strecha dataset
                with different descriptors: SIFT, DeepDesc, Tfeat. DeepDesc and Tfeat are CNN based descriptors trained an existing dataset for descriptor learning. Our multi-resolution model trained on our
                proposed dataset obtains more no of point correspondences which leads to denser reconstructions indicated by a higher number of reconstructed points.
              </h6>
            </div>
          </section>
        </div>
        <div class="mdl-layout__tab-panel" id="semisuppose">
          <section class="section--center mdl-grid mdl-grid--no-spacing">
            <div class="mdl-cell mdl-cell--12-col">
              <h4>Features</h4>
              Minim duis incididunt est cillum est ex occaecat consectetur. Qui sint ut et qui nisi cupidatat. Reprehenderit nostrud proident officia exercitation anim et pariatur ex.
              <ul class="toc">
                <h4>Contents</h4>
                <a href="#lorem1">Lorem ipsum</a>
                <a href="#lorem2">Lorem ipsum</a>
                <a href="#lorem3">Lorem ipsum</a>
                <a href="#lorem4">Lorem ipsum</a>
                <a href="#lorem5">Lorem ipsum</a>
              </ul>

              <h5 id="lorem1">Lorem ipsum dolor sit amet</h5>
              Excepteur et pariatur officia veniam anim culpa cupidatat consequat ad velit culpa est non.
              <ul>
                <li>Nisi qui nisi duis commodo duis reprehenderit consequat velit aliquip.</li>
                <li>Dolor consectetur incididunt in ipsum laborum non et irure pariatur excepteur anim occaecat officia sint.</li>
                <li>Lorem labore proident officia excepteur do.</li>
              </ul>

              <p>
                Sit qui est voluptate proident minim cillum in aliquip cupidatat labore pariatur id tempor id. Proident occaecat occaecat sint mollit tempor duis dolor cillum anim. Dolore sunt ea mollit fugiat in aliqua consequat nostrud aliqua ut irure in dolore. Proident aliqua culpa sint sint exercitation. Non proident occaecat reprehenderit veniam et proident dolor id culpa ea tempor do dolor. Nulla adipisicing qui fugiat id dolor. Nostrud magna voluptate irure veniam veniam labore ipsum deserunt adipisicing laboris amet eu irure. Sunt dolore nisi velit sit id. Nostrud voluptate labore proident cupidatat enim amet Lorem officia magna excepteur occaecat eu qui. Exercitation culpa deserunt non et tempor et non.
              </p>
              <p>
                Do dolor eiusmod eu mollit dolore nostrud deserunt cillum irure esse sint irure fugiat exercitation. Magna sit voluptate id in tempor elit veniam enim cupidatat ea labore elit. Aliqua pariatur eu nulla labore magna dolore mollit occaecat sint commodo culpa. Eu non minim duis pariatur Lorem quis exercitation. Sunt qui ex incididunt sit anim incididunt sit elit ad officia id.
              </p>
              <p id="lorem2">
                Tempor voluptate ex consequat fugiat aliqua. Do sit et reprehenderit culpa deserunt culpa. Excepteur quis minim mollit irure nulla excepteur enim quis in laborum. Aliqua elit voluptate ad deserunt nulla reprehenderit adipisicing sint. Est in eiusmod exercitation esse commodo. Ea reprehenderit exercitation veniam adipisicing minim nostrud. Veniam dolore ex ea occaecat non enim minim id ut aliqua adipisicing ad. Occaecat excepteur aliqua tempor cupidatat aute dolore deserunt ipsum qui incididunt aliqua occaecat sit quis. Culpa sint aliqua aliqua reprehenderit veniam irure fugiat ea ad.
              </p>
              <p>
                Eu minim fugiat laborum irure veniam Lorem aliqua enim. Aliqua veniam incididunt consequat irure consequat tempor do nisi deserunt. Elit dolore ad quis consectetur sint laborum anim magna do nostrud amet. Ea nulla sit consequat quis qui irure dolor. Sint deserunt excepteur consectetur magna irure. Dolor tempor exercitation dolore pariatur incididunt ut laboris fugiat ipsum sunt veniam aute sunt labore. Non dolore sit nostrud eu ad excepteur cillum eu ex Lorem duis.
              </p>
              <p>
                Id occaecat velit non ipsum occaecat aliqua quis ut. Eiusmod est magna non esse est ex incididunt aute ullamco. Cillum excepteur sint ipsum qui quis velit incididunt amet. Qui deserunt anim enim laborum cillum reprehenderit duis mollit amet ad officia enim. Minim sint et quis aliqua aliqua do minim officia dolor deserunt ipsum laboris. Nulla nisi voluptate consectetur est voluptate et amet. Occaecat ut quis adipisicing ad enim. Magna est magna sit duis proident veniam reprehenderit fugiat reprehenderit enim velit ex. Ullamco laboris culpa irure aliquip ad Lorem consequat veniam ad ipsum eu. Ipsum culpa dolore sunt officia laborum quis.
              </p>

              <h5 id="lorem3">Lorem ipsum dolor sit amet</h5>

              <p id="lorem4">
                Eiusmod nulla aliquip ipsum reprehenderit nostrud non excepteur mollit amet esse est est dolor. Dolore quis pariatur sit consectetur veniam esse ullamco duis Lorem qui enim ut veniam. Officia deserunt minim duis laborum dolor in velit pariatur commodo ullamco eu. Aute adipisicing ad duis labore laboris do mollit dolor cillum sunt aliqua ullamco. Esse tempor quis cillum consequat reprehenderit. Adipisicing proident anim eu sint elit aliqua anim dolore cupidatat fugiat aliquip qui.
              </p>
              <p id="lorem5">
                Nisi eiusmod esse cupidatat excepteur exercitation ipsum reprehenderit nostrud deserunt aliqua ullamco. Anim est irure commodo eiusmod pariatur officia. Est dolor ipsum excepteur magna aliqua ad veniam irure qui occaecat eiusmod aute fugiat commodo. Quis mollit incididunt amet sit minim velit eu fugiat voluptate excepteur. Sit minim id pariatur ex cupidatat cupidatat nostrud nostrud ipsum.
              </p>
              <p>
                Enim ea officia excepteur ad veniam id reprehenderit eiusmod esse mollit consequat. Esse non aute ullamco Lorem aliqua qui dolore irure eiusmod aute aliqua proident labore aliqua. Ipsum voluptate voluptate exercitation laborum deserunt nulla elit aliquip et minim ex veniam. Duis cupidatat aute sunt officia mollit dolor ad elit ad aute labore nostrud duis pariatur. In est sint voluptate consectetur velit ea non labore. Ut duis ea aliqua consequat nulla laboris fugiat aute id culpa proident. Minim eiusmod laboris enim Lorem nisi excepteur mollit voluptate enim labore reprehenderit officia mollit.
              </p>
              <p>
                Cupidatat labore nisi ut sunt voluptate quis sunt qui ad Lorem esse nisi. Ex esse velit ullamco incididunt occaecat dolore veniam tempor minim adipisicing amet. Consequat in exercitation est elit anim consequat cillum sint labore cillum. Aliquip mollit laboris ad labore anim.
              </p>
            </div>
          </section>
        </div>
        <div class="mdl-layout__tab-panel" id="unsuptex">
          <section class="section--center mdl-grid mdl-grid--no-spacing">
            <div class="mdl-cell mdl-cell--12-col">
              <h4>Features</h4>
              Minim duis incididunt est cillum est ex occaecat consectetur. Qui sint ut et qui nisi cupidatat. Reprehenderit nostrud proident officia exercitation anim et pariatur ex.
              <ul class="toc">
                <h4>Contents</h4>
                <a href="#lorem1">Lorem ipsum</a>
                <a href="#lorem2">Lorem ipsum</a>
                <a href="#lorem3">Lorem ipsum</a>
                <a href="#lorem4">Lorem ipsum</a>
                <a href="#lorem5">Lorem ipsum</a>
              </ul>

              <h5 id="lorem1">Lorem ipsum dolor sit amet</h5>
              Excepteur et pariatur officia veniam anim culpa cupidatat consequat ad velit culpa est non.
              <ul>
                <li>Nisi qui nisi duis commodo duis reprehenderit consequat velit aliquip.</li>
                <li>Dolor consectetur incididunt in ipsum laborum non et irure pariatur excepteur anim occaecat officia sint.</li>
                <li>Lorem labore proident officia excepteur do.</li>
              </ul>

              <p>
                Sit qui est voluptate proident minim cillum in aliquip cupidatat labore pariatur id tempor id. Proident occaecat occaecat sint mollit tempor duis dolor cillum anim. Dolore sunt ea mollit fugiat in aliqua consequat nostrud aliqua ut irure in dolore. Proident aliqua culpa sint sint exercitation. Non proident occaecat reprehenderit veniam et proident dolor id culpa ea tempor do dolor. Nulla adipisicing qui fugiat id dolor. Nostrud magna voluptate irure veniam veniam labore ipsum deserunt adipisicing laboris amet eu irure. Sunt dolore nisi velit sit id. Nostrud voluptate labore proident cupidatat enim amet Lorem officia magna excepteur occaecat eu qui. Exercitation culpa deserunt non et tempor et non.
              </p>
              <p>
                Do dolor eiusmod eu mollit dolore nostrud deserunt cillum irure esse sint irure fugiat exercitation. Magna sit voluptate id in tempor elit veniam enim cupidatat ea labore elit. Aliqua pariatur eu nulla labore magna dolore mollit occaecat sint commodo culpa. Eu non minim duis pariatur Lorem quis exercitation. Sunt qui ex incididunt sit anim incididunt sit elit ad officia id.
              </p>
              <p id="lorem2">
                Tempor voluptate ex consequat fugiat aliqua. Do sit et reprehenderit culpa deserunt culpa. Excepteur quis minim mollit irure nulla excepteur enim quis in laborum. Aliqua elit voluptate ad deserunt nulla reprehenderit adipisicing sint. Est in eiusmod exercitation esse commodo. Ea reprehenderit exercitation veniam adipisicing minim nostrud. Veniam dolore ex ea occaecat non enim minim id ut aliqua adipisicing ad. Occaecat excepteur aliqua tempor cupidatat aute dolore deserunt ipsum qui incididunt aliqua occaecat sit quis. Culpa sint aliqua aliqua reprehenderit veniam irure fugiat ea ad.
              </p>
              <p>
                Eu minim fugiat laborum irure veniam Lorem aliqua enim. Aliqua veniam incididunt consequat irure consequat tempor do nisi deserunt. Elit dolore ad quis consectetur sint laborum anim magna do nostrud amet. Ea nulla sit consequat quis qui irure dolor. Sint deserunt excepteur consectetur magna irure. Dolor tempor exercitation dolore pariatur incididunt ut laboris fugiat ipsum sunt veniam aute sunt labore. Non dolore sit nostrud eu ad excepteur cillum eu ex Lorem duis.
              </p>
              <p>
                Id occaecat velit non ipsum occaecat aliqua quis ut. Eiusmod est magna non esse est ex incididunt aute ullamco. Cillum excepteur sint ipsum qui quis velit incididunt amet. Qui deserunt anim enim laborum cillum reprehenderit duis mollit amet ad officia enim. Minim sint et quis aliqua aliqua do minim officia dolor deserunt ipsum laboris. Nulla nisi voluptate consectetur est voluptate et amet. Occaecat ut quis adipisicing ad enim. Magna est magna sit duis proident veniam reprehenderit fugiat reprehenderit enim velit ex. Ullamco laboris culpa irure aliquip ad Lorem consequat veniam ad ipsum eu. Ipsum culpa dolore sunt officia laborum quis.
              </p>

              <h5 id="lorem3">Lorem ipsum dolor sit amet</h5>

              <p id="lorem4">
                Eiusmod nulla aliquip ipsum reprehenderit nostrud non excepteur mollit amet esse est est dolor. Dolore quis pariatur sit consectetur veniam esse ullamco duis Lorem qui enim ut veniam. Officia deserunt minim duis laborum dolor in velit pariatur commodo ullamco eu. Aute adipisicing ad duis labore laboris do mollit dolor cillum sunt aliqua ullamco. Esse tempor quis cillum consequat reprehenderit. Adipisicing proident anim eu sint elit aliqua anim dolore cupidatat fugiat aliquip qui.
              </p>
              <p id="lorem5">
                Nisi eiusmod esse cupidatat excepteur exercitation ipsum reprehenderit nostrud deserunt aliqua ullamco. Anim est irure commodo eiusmod pariatur officia. Est dolor ipsum excepteur magna aliqua ad veniam irure qui occaecat eiusmod aute fugiat commodo. Quis mollit incididunt amet sit minim velit eu fugiat voluptate excepteur. Sit minim id pariatur ex cupidatat cupidatat nostrud nostrud ipsum.
              </p>
              <p>
                Enim ea officia excepteur ad veniam id reprehenderit eiusmod esse mollit consequat. Esse non aute ullamco Lorem aliqua qui dolore irure eiusmod aute aliqua proident labore aliqua. Ipsum voluptate voluptate exercitation laborum deserunt nulla elit aliquip et minim ex veniam. Duis cupidatat aute sunt officia mollit dolor ad elit ad aute labore nostrud duis pariatur. In est sint voluptate consectetur velit ea non labore. Ut duis ea aliqua consequat nulla laboris fugiat aute id culpa proident. Minim eiusmod laboris enim Lorem nisi excepteur mollit voluptate enim labore reprehenderit officia mollit.
              </p>
              <p>
                Cupidatat labore nisi ut sunt voluptate quis sunt qui ad Lorem esse nisi. Ex esse velit ullamco incididunt occaecat dolore veniam tempor minim adipisicing amet. Consequat in exercitation est elit anim consequat cillum sint labore cillum. Aliquip mollit laboris ad labore anim.
              </p>
            </div>
          </section>
        </div>
        <footer class="mdl-mega-footer">
        </footer>
      </main>
    </div>
    <script src="https://code.getmdl.io/1.3.0/material.min.js"></script>
  </body>
</html>
